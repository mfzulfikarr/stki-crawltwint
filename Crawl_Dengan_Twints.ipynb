{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukajb1qTRnHh"
      },
      "outputs": [],
      "source": [
        "!git clone --depth=1 https://github.com/twintproject/twint.git\n",
        "%cd twint\n",
        "!pip3 install . -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install aiohttp==3.7.0"
      ],
      "metadata": {
        "id": "Mge-Q_L3Ryuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nest_asyncio"
      ],
      "metadata": {
        "id": "FmIjJ1H0SM9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "import twint\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import os"
      ],
      "metadata": {
        "id": "ZyDl71aRR9Tw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = twint.Config()\n",
        "c.Username = 'ATCS_DISHUB_DIY'\n",
        "c.Pandas = True\n",
        "#c.Limit = 10\n",
        "twint.run.Search(c)"
      ],
      "metadata": {
        "id": "zJjX5_sRWH55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Tweets_df = twint.storage.panda.Tweets_df\n",
        "#Tweets_df.head()"
      ],
      "metadata": {
        "id": "JhkfGpD_SbFy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Tweets_df = Tweets_df.drop(['conversation_id', 'created_at', 'timezone', 'id', 'place', 'language', 'hashtags', 'cashtags', 'user_id', 'user_id_str', 'username', 'name', 'day', 'hour', 'urls', 'video', 'thumbnail', 'retweet', 'nlikes', 'nreplies', 'nretweets', 'quote_url', 'search', 'near', 'geo', 'source', 'user_rt_id', 'user_rt', 'retweet_id', 'reply_to', 'retweet_date', 'translate', 'trans_src', 'trans_dest'], axis = 1)\n",
        "Tweets_df = Tweets_df.dropna(axis = 1)"
      ],
      "metadata": {
        "id": "lmJNcRZj6MhX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Tweets_df.to_excel('CrawlTwint.xlsx', index = False)"
      ],
      "metadata": {
        "id": "fN07i85N8ZY2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import files\n",
        "#files.download(\"CrawlTwint.xlsx\")"
      ],
      "metadata": {
        "id": "AZi-thiK8wlX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Tweets_df['date'] = Tweets_df['date'].str.replace(r'\\D', '', case=False)"
      ],
      "metadata": {
        "id": "A2R0HnFKyVI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Tweets_df['date'])"
      ],
      "metadata": {
        "id": "XXq6k_Kjypjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convString = pd.to_datetime(Tweets_df['date'], format='%Y%m%d%H%M%S')"
      ],
      "metadata": {
        "id": "EhPi5r9V-L_O"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(convString)"
      ],
      "metadata": {
        "id": "GuZmqdtfzPBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Tweets_df['date'] = convString.dt.tz_localize('UTC').dt.tz_convert('Asia/Jakarta')"
      ],
      "metadata": {
        "id": "IgMTejjozWqI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Tweets_df['date'])"
      ],
      "metadata": {
        "id": "C0ypA2kozaho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Tweets_df['date'] = Tweets_df['date'].dt.tz_localize(None)\n",
        "Tweets_df['date'] = Tweets_df['date'].astype(str)\n",
        "Tweets_df.to_excel('TwintTimeCleaning.xlsx', index = False)"
      ],
      "metadata": {
        "id": "KBlWUbiN0Fxm"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import files\n",
        "#files.download(\"TwintTimeCleaning.xlsx\")"
      ],
      "metadata": {
        "id": "9iY-VvDT0Yj6"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key_value = [\"jalanan\",\n",
        "    \"lalin\",\n",
        "    \"lalu lintas\",\n",
        "    \"lancar\",\n",
        "    \"macet\",\n",
        "    \"padat\",\n",
        "    \"ramai\",\n",
        "    \"tersendat\"]\n",
        "df = pd.read_excel('TwintTimeCleaning.xlsx')\n",
        "df = df[df['tweet'].str.contains('|'. join(key_value))]\n",
        "df['tweet'] = df['tweet'].str.replace('http\\S+|www.\\S+', '', case=False)\n",
        "df['tweet'] = df['tweet'].str.replace('&amp;', 'dan', case=False)"
      ],
      "metadata": {
        "id": "pBZElAHB8E2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "9pNfmTf9y0M6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_excel('TwintFullClean.xlsx', index = False)"
      ],
      "metadata": {
        "id": "wvfiTJ8F8pcQ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfProcess = pd.read_excel('TwintFullClean.xlsx')\n",
        "dfStatus = pd.read_excel('DataNonJalan.xlsx')\n",
        "#dfJalan = pd.read_excel('DataSimpangDIY.xlsx')\n",
        "dfJalan = pd.read_excel('DataSimpangDIYNormal.xlsx')\n",
        "\n",
        "listKondisi = dfStatus['Kondisi'].tolist()\n",
        "listKondisi = [x for x in listKondisi if pd.isnull(x) == False]\n",
        "\n",
        "listKeterangan = dfStatus['Peristiwa'].tolist()\n",
        "listKeterangan = [x for x in listKeterangan if pd.isnull(x) == False]\n",
        "\n",
        "listCuaca = dfStatus['Cuaca'].tolist()\n",
        "listCuaca = [x for x in listCuaca if pd.isnull(x) == False]\n",
        "\n",
        "dfProcess = dfProcess[dfProcess['tweet'].str.contains('|'. join(listKondisi))]\n",
        "\n",
        "print(listKondisi)\n",
        "print(listKeterangan)\n",
        "print(listCuaca)"
      ],
      "metadata": {
        "id": "pk_lSlBM3Woq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "timeConv = pd.to_datetime(dfProcess['date'])\n",
        "timeConv = timeConv.reset_index(drop=True)\n",
        "dftimeConv = timeConv.dt.strftime('%Y-%b-%d')\n",
        "dftimeYear = timeConv.dt.strftime('%Y')\n",
        "dftimeMonth = timeConv.dt.strftime('%B')\n",
        "dftimeDay = timeConv.dt.day_name()\n",
        "print(dftimeDay)\n",
        "print(dftimeMonth)\n",
        "print(dftimeYear)\n",
        "print(dftimeConv)\n",
        "print(timeConv)"
      ],
      "metadata": {
        "id": "OFpWC9z599VL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# simpangList = dfJalan['simpang'].tolist()\n",
        "# arahList = dfJalan['arah'].tolist()\n",
        "simpangList = dfJalan['Simpang'].tolist()\n",
        "arahList = dfJalan['Arah'].tolist()\n",
        "\n",
        "simpangList = [x for x in simpangList if pd.isnull(x) == False]\n",
        "arahList = [x for x in arahList if pd.isnull(x) == False]\n",
        "streetList = simpangList + arahList\n",
        "streetList = list(dict.fromkeys(streetList))\n",
        "print(streetList)"
      ],
      "metadata": {
        "id": "LakIvKy8KXcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfInsert = dfProcess.insert(1,\"Date\", np.nan)\n",
        "dfInsert = dfProcess.insert(2,\"Year\", np.nan)\n",
        "dfInsert = dfProcess.insert(3,\"Month\", np.nan)\n",
        "dfInsert = dfProcess.insert(4,\"Day\", np.nan)\n",
        "dfInsert = dfProcess.insert(5,\"Waktu\", np.nan)\n",
        "dfInsert = dfProcess.insert(6,\"Dari\", np.nan)\n",
        "dfInsert = dfProcess.insert(7,\"Arah\", np.nan)\n",
        "dfInsert = dfProcess.insert(8,\"Kondisi\", np.nan)\n",
        "dfInsert = dfProcess.insert(10,\"Hambatan\", np.nan)\n",
        "dfProcess = dfProcess.reset_index(drop=True)\n",
        "dftimeConv = dftimeConv.reset_index(drop=True)\n",
        "dfProcess"
      ],
      "metadata": {
        "id": "kDjVRLd-FIkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweet = dfProcess['tweet'].tolist()\n",
        "\n",
        "listDate = []\n",
        "listTime = []\n",
        "listFrom = []\n",
        "listTo = []\n",
        "listCond = []\n",
        "listCause = []\n",
        "\n",
        "for n in range(0, len(tweet), +1):\n",
        "  newList = tweet[n]\n",
        "  newStr = newList\n",
        "\n",
        "  fixedStr = newStr\n",
        "  strToReplace = {'gangguan mesin': 'mogok', 'demo': 'demonstrasi', \n",
        "                  'sp':'simpang', 'disimpang':'simpang', 'berlawanan':'sebaliknya', 'segala arah':'',\n",
        "                  'kidsfun':'Kidsfun', 'kids fun':'Kidsfun', 'Kids fun':'Kidsfun', 'Kids Fun':'Kidsfun',\n",
        "                  'jatikencana':'Jati Kencana', 'Jatikencana':'Jati Kencana',\n",
        "                  'pelemgurih':'Pelem Gurih', 'pelem gurih':'Pelem Gurih', 'Pelem gurih':'Pelem Gurih', 'pelem Gurih':'Pelem Gurih',\n",
        "                  'blok o':'Blok O', 'blok O':'Blok O', 'Blok o':'Blok O', 'BLOK O':'Blok O', 'BLOK o':'Blok O',\n",
        "                  'maguwo':'Maguwoharjo', 'Maguwo':'Maguwoharjo', 'MAGUWO':'Maguwoharjo', 'maguwoharjo':'Maguwoharjo', 'MAGUWOHARJO':'Maguwoharjo', 'maguwo harjo':'Maguwoharjo', 'Maguwo harjo':'Maguwoharjo', 'maguwo Harjo':'Maguwoharjo', 'Maguwo Harjo':'Maguwoharjo',\n",
        "                  'kotagedhe':'Kota Gedhe', 'Kotagedhe':'Kota Gedhe', 'kotaGedhe':'Kota Gedhe', 'KOTAgedhe':'Kota Gedhe', 'kotaGEDHE':'Kota Gedhe', 'kota gedhe':'Kota Gedhe', 'kota Gedhe':'Kota Gedhe', 'KOTA gedhe':'Kota Gedhe', 'kota GEDHE':'Kota Gedhe', ''\n",
        "                  'mm ugm':'MM UGM', 'MM ugm':'MM UGM', 'mmugm':'MM UGM', 'mm UGM':'MM UGM', 'MMugm':'MM UGM', 'mmUGM':'MM UGM', 'MMUGM':'MM UGM',\n",
        "                  'tempel':'Tempel', 'giwangan':'Giwangan', 'gamping':'Gamping', 'demangan':'Demangan', 'bandara':'Bandara',\n",
        "                  'seturan':'Seturan', 'ngasem':'Ngasem', 'wojo':'Wojo', 'uin':'UIN', 'pogung':'Pogung',\n",
        "                  'kentungan':'Kentungan', 'tugu':'Tugu', 'gramedia':'Gramedia', 'galeria':'Galeria',\n",
        "                  'condongcatur':'Condongcatur', 'CondongCatur':'Condongcatur',\n",
        "                  'druwo':'Druwo',\n",
        "                  'patran':'Patran',\n",
        "                  'timur':'Timur',\n",
        "                  'barat':'Barat',\n",
        "                  'selatan':'Selatan',\n",
        "                  'utara':'Utara'}\n",
        "  for key, value in strToReplace.items():\n",
        "      fixedStr = fixedStr.replace(key, value)\n",
        "      fixedStr = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", fixedStr)\n",
        "\n",
        "#>>>Proses splitting arah jalan dan splitting waktu<<<\n",
        "  splitList = fixedStr.split('menuju' and 'arah' or 'ke')\n",
        "  print(splitList)\n",
        "  # lenKond = len(splitKond)\n",
        "  # print(splitKond)\n",
        "\n",
        "  tweetTime = dfProcess['date'].tolist()\n",
        "  timeTweet = tweetTime[n]\n",
        "  splitTime = timeTweet.split(' ')\n",
        "  #print(splitTime)\n",
        "\n",
        "  lenList = len(splitList)\n",
        "  emptyStr = '-'\n",
        "\n",
        "  tglTweet = dftimeConv[n]\n",
        "  waktuTweet = splitTime[1]\n",
        "\n",
        "  #print('Date: ' + tglTweet)\n",
        "  #print('Tweet Time: ' + waktuTweet)\n",
        "\n",
        "  print('Tweet: ' + newList)\n",
        "\n",
        "#>>>Start proses ekstraksi teks dari twitter<<<\n",
        "  if (lenList > 1):\n",
        "    fromList = splitList[0]\n",
        "    fromWord = [word for word in streetList if word in fromList]\n",
        "    toList = splitList[1]\n",
        "    toWord = [word for word in streetList if word in toList]\n",
        "    fromStr = \", \".join(fromWord)\n",
        "    toStr = \", \".join(toWord)\n",
        "    print('From: ' + fromStr)\n",
        "    print('To: ' + toStr)\n",
        "  else:\n",
        "    fromList = splitList[0]\n",
        "    fromWord = [word for word in streetList if word in fromList]\n",
        "    fromStr = \" \".join(fromWord)\n",
        "    toStr = emptyStr\n",
        "    print('From: ' + fromStr)\n",
        "    print('To: ' + toStr)\n",
        "\n",
        "  tweetKondisi = [x for x in listKondisi if x in newList]\n",
        "  kondisiStr = \" \".join(tweetKondisi)\n",
        "  if 'ramai lancar' in newList:\n",
        "    kondisiStr = 'ramai lancar'\n",
        "  elif 'lancar' in newList:\n",
        "    kondisiStr = 'lancar'\n",
        "  kondisiStrrev = emptyStr\n",
        "  # print('Condition: ' + kondisiStr)\n",
        "\n",
        "  # if (lenKond > 1):\n",
        "  #   kondList = splitKond[1]\n",
        "  #   tweetKondisirev = [x for x in listKondisi if x in kondList]\n",
        "  #   kondisiStrrev = \" \".join(tweetKondisirev)\n",
        "  #   if 'ramai lancar' in kondList:\n",
        "  #     kondisiStrrev = 'ramai lancar'\n",
        "  #   elif 'lancar' in kondList:\n",
        "  #     kondisiStrrev = 'lancar'\n",
        "  #   print('Opposite: ' + kondisiStrrev)\n",
        "\n",
        "  emptyList = []\n",
        "  tweetKeterangan = [x for x in listKeterangan if x in fixedStr]\n",
        "  if (tweetKeterangan == emptyList):\n",
        "    keteranganStr = emptyStr\n",
        "  else:\n",
        "    keteranganStr = \" \".join(tweetKeterangan)\n",
        "  #print('Cause: ' + keteranganStr)\n",
        "\n",
        "  # tweetCuaca = [x for x in listCuaca if x in fixedStr]\n",
        "  # if (tweetCuaca == emptyList):\n",
        "  #   cuacaStr = emptyStr\n",
        "  # else:\n",
        "  #   cuacaStr = \" \".join(tweetCuaca)\n",
        "  # #print('Weather: ' + cuacaStr)\n",
        "  # #print('\\n')\n",
        "\n",
        "  listDate.append(tglTweet)\n",
        "  listTime.append(waktuTweet)\n",
        "  listFrom.append(fromStr)\n",
        "  listTo.append(toStr)\n",
        "  listCond.append(kondisiStr)\n",
        "  listCause.append(keteranganStr)\n",
        "\n",
        "#>>>End proses ekstraksi teks dari twitter<<<\n",
        "\n",
        "#print(listFrom)\n",
        "print(listTo)\n",
        "#print(listCond)\n",
        "#print(listCause)\n",
        "#print(listWeather)\n",
        "\n",
        "#>>>Memasukkan hasil proses ekstraksi ke tabel<<<\n",
        "dfFinalTweet = dfProcess.assign(Date = dftimeConv, Waktu = listTime, Year = dftimeYear, Month = dftimeMonth, Day = dftimeDay, Dari = listFrom, Arah = listTo, Kondisi = listCond, Hambatan = listCause)\n",
        "dfFinalTweet = dfFinalTweet.drop(['date'], axis=1)\n",
        "dfFinalTweet = dfFinalTweet.rename(columns = {'tweet':'Tweet'})\n",
        "print(dfFinalTweet)"
      ],
      "metadata": {
        "id": "LweYrnW-_dTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfFinalTweet.to_excel('DatasetTweetFinal.xlsx', index = False)"
      ],
      "metadata": {
        "id": "YSLhXDj_C59Q"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfFinalTweet.to_csv('DatasetTweetFinal.csv', index = False)"
      ],
      "metadata": {
        "id": "9GmMxgAiBJYM"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read DataFrame\n",
        "data = pd.read_csv(\"DatasetTweetFinal.csv\")\n",
        "!mkdir datasets\n",
        "root = 'datasets'\n",
        "for (Date), group in data.groupby(['Date']):\n",
        "     group.to_csv(root + '/' + f'{Date}.csv', index=False)\n",
        "\n",
        "# print(pd.read_csv(\"2022-Sep-22.csv\"))\n",
        "# print(pd.read_csv(\"2022-Sep-17.csv\"))"
      ],
      "metadata": {
        "id": "RnH9Zep1Q_Hz"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docMaster = []\n",
        "for file in os.listdir('datasets'):\n",
        "  if file.endswith ('.csv'):\n",
        "    docMaster.append (pd.read_csv(os.path.join('datasets', file)))"
      ],
      "metadata": {
        "id": "16muzArU9Ya4"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docMain = pd.concat(docMaster, axis=0)\n",
        "dfdocMain = docMain.to_csv('DocFull.csv', index = True)\n",
        "dfdocMain = pd.read_csv('DocFull.csv')\n",
        "dfdocMain = dfdocMain.dropna(axis = 0)\n",
        "\n",
        "dfdocMain = dfdocMain.apply(lambda x: x.replace(strToReplace, regex=True))\n",
        "listdocMain = dfdocMain['Tweet'].tolist()\n",
        "print(dfdocMain)\n",
        "print(listdocMain)\n",
        "\n",
        "# for n in range(0, len(listdocMain), +1):\n",
        "#   newListdoc = tweet[n]\n",
        "#   newStrdoc = newListdoc\n",
        "#   fixedStr = newStrdoc\n",
        "#   for key, value in strToReplace.items():\n",
        "#       fixedStr = fixedStr.replace(key, value)\n",
        "#       fixedStr = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", fixedStr)\n",
        "#       # dfdocMain['Tweet'] = fixedStr\n",
        "#       listfixedStr = list(fixedStr.split(\" \"))\n",
        "#       df = df[df['tweet'].str.contains('|'. join(key_value))]\n",
        "# print(listfixedStr)\n",
        "# print(fixedStr)\n",
        "# print(newListdoc)\n",
        "# print(listdocMain)"
      ],
      "metadata": {
        "id": "YLh8NtHn9pTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = doc1 + doc2 + doc3 + doc4 + doc5\n",
        "arrdocs = np.array(listdocMain)"
      ],
      "metadata": {
        "id": "29nbUAEhoCvD"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "streetList2 = simpangList + arahList"
      ],
      "metadata": {
        "id": "eoHrYyV0rvov"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "streetSet = set(streetList2)\n",
        "arrStreet = np.array(streetList2)"
      ],
      "metadata": {
        "id": "kqOJgdwsoIik"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inverted_index = {}\n",
        "\n",
        "# for i, streetSet in enumerate(docs):\n",
        "#   for term in streetSet:\n",
        "#     if term in inverted_index:\n",
        "#       inverted_index[term].add(i)\n",
        "#     else: inverted_index[term] = {i}\n",
        "\n",
        "# inverted_index"
      ],
      "metadata": {
        "id": "73UhJPl_tWh9"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(arrdocs)\n",
        "invIndex = {}\n",
        "for i in range(len(dfdocMain)):\n",
        "    check = arrdocs[i]\n",
        "    for item in arrStreet:\n",
        "        if item in check:\n",
        "            if item not in invIndex:\n",
        "                invIndex[item] = []\n",
        "            if item in invIndex:\n",
        "                invIndex[item].append(i+1)\n",
        "\n",
        "invIndex"
      ],
      "metadata": {
        "id": "2eeSuzZj4qeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# posting_list = inverted_index['Seturan']\n",
        "# posting_list"
      ],
      "metadata": {
        "id": "tFXnqa2tvLPd"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# path = 'datasets'\n",
        "# filenames = os.listdir(path)\n",
        "# # print(filenames)\n",
        "\n",
        "# def is_name_in_csv(word,csv_file):\n",
        "#   with open(csv_file,\"r\") as f:\n",
        "#     data = f.read()\n",
        "#   return bool(re.search(word, data))\n",
        "\n",
        "# list_file_csv = filenames\n",
        "# word = ('|'. join(streetList))\n",
        "# for csv_file in list_file_csv:\n",
        "#   if is_name_in_csv(word,csv_file):\n",
        "#     print(f\"Found {word} in {csv_file}\")\n",
        "#   else:\n",
        "#     print(f\"Finished. Can't find any more data with that word\")\n",
        "#     break"
      ],
      "metadata": {
        "id": "b3qRQ1Jqr1aA"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "inv_index = defaultdict(list)\n",
        "for doc, words in zip(\n",
        "        dfdocMain['Date'],\n",
        "        dfdocMain['Dari'].str.findall('|'. join(listFrom)).map(set)):\n",
        "    for word in words:\n",
        "        inv_index[word].append(doc)\n",
        "print(inv_index)"
      ],
      "metadata": {
        "id": "mn_lRkQC7mGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(tweet)\n",
        "# arr_tweet = np.array(tweet)\n",
        "# arr_streetList = np.array(streetList)\n",
        "# print(arr_streetList)\n",
        "# #print(arr_tweet)\n",
        "# dict = {}\n",
        "\n",
        "# for i in range(len(tweet)):\n",
        "#     check = arr_tweet[i].lower()\n",
        "#     for item in arr_streetList:\n",
        "#         if item in check:\n",
        "#             if item not in dict:\n",
        "#                 dict[item] = []\n",
        "#             if item in dict:\n",
        "#                 dict[item].append(i+1)\n",
        "\n",
        "# dict"
      ],
      "metadata": {
        "id": "TaDBM5S9vVxX"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfFinish = pd.read_excel('DatasetTweetFinal.xlsx')\n",
        "dfFinish = dfFinish.dropna(axis=0)\n",
        "fixedListFrom = list(dict.fromkeys(listFrom))\n",
        "# print(fixedListFrom)\n",
        "greet = \"Hi! Saya akan mengambil tweet Jakarta Utara dari TMCPoldaMetroJaya. Coba tulis nama jalannya disini ya!\"\n",
        "print(greet)\n",
        "\n",
        "def posindexing(inputstr):\n",
        "  from collections import defaultdict\n",
        "  ind = inputstr\n",
        "  pos_index = defaultdict(list)\n",
        "  for doc, words in zip(\n",
        "      dfdocMain['Date'],\n",
        "      dfdocMain['Dari'].str.findall(ind).map(set)):\n",
        "    for word in words:\n",
        "        pos_index[word].append(doc)\n",
        "  print(pos_index)\n",
        "\n",
        "def indexing(inputstr):\n",
        "  invIndex = {}\n",
        "  for i in range(len(dfdocMain)):\n",
        "      check = arrdocs[i]\n",
        "      for item in arrStreet:\n",
        "          if item in check:\n",
        "              if item not in invIndex:\n",
        "                  invIndex[item] = []\n",
        "              if item in invIndex:\n",
        "                  invIndex[item].append(i+1)\n",
        "  x = invIndex[inputstr]\n",
        "  print(x)\n",
        "\n",
        "def start():\n",
        "  print('Coba masukkan nama jalan ')\n",
        "  inputstr = input('')\n",
        "  checkWord = [word for word in fixedListFrom if word in inputstr]\n",
        "  fixedInput = ''.join(checkWord)\n",
        "  print(checkWord)\n",
        "  dfBot = dfFinish[dfFinish['Dari'].str.contains(inputstr)]\n",
        "  posindexing(inputstr)\n",
        "  indexing(inputstr)\n",
        "  print('\\n')\n",
        "\n",
        "  showDate = dfBot['Date'].tolist()\n",
        "  showYear = dfBot['Year'].tolist()\n",
        "  showMonth = dfBot['Month'].tolist()\n",
        "  showDay = dfBot['Day'].tolist()\n",
        "  showTime = dfBot['Waktu'].tolist()\n",
        "  showTweet = dfBot['Tweet'].tolist()\n",
        "  showFrom = dfBot['Dari'].tolist()\n",
        "  showTo = dfBot['Arah'].tolist()\n",
        "  showCond = dfBot['Kondisi'].tolist()\n",
        "  showCause = dfBot['Hambatan'].tolist()\n",
        "  showAll = dfBot.values.tolist()\n",
        "  showAll = sum(showAll, [])\n",
        "  showAll = ' '.join(map(str, showAll))\n",
        "\n",
        "  if inputstr in showAll:\n",
        "    print(\"Yay! Saya menemukan beberapa Tweet!\\n\")\n",
        "    for n in range(0, len(showTweet), +1):\n",
        "      print('Date: ' + str(showDate[n]))\n",
        "      print('Year: ' + str(showYear[n]))\n",
        "      print('Month: ' + showMonth[n])\n",
        "      print('Day: ' + showDay[n])\n",
        "      print('Time: ' + showTime[n])\n",
        "      print('Tweet: ' + showTweet[n])\n",
        "      print('From: ' + showFrom[n])\n",
        "      print('To: ' + showTo[n])\n",
        "      print('Condition: ' + showCond[n])\n",
        "      print('Cause: ' + str(showCause[n]))\n",
        "\n",
        "      print('\\n')\n",
        "\n",
        "  else:\n",
        "    print('Hmm... Sepertinya TMC Polda Metro Jaya belum Tweet jalan itu. Bagaimana dengan jalan lainnya?')\n",
        "    start()\n",
        "start()"
      ],
      "metadata": {
        "id": "K2sNFRJRir7P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}